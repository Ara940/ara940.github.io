@inproceedings{gal2016dropout,
  title={Dropout as a bayesian approximation: Representing model uncertainty in deep learning},
  author={Gal, Yarin and Ghahramani, Zoubin},
  booktitle={international conference on machine learning},
  pages={1050--1059},
  year={2016},
  organization={PMLR}
}



%%%%%%%%%%%%%%%% Diffusion models
@misc{ling2022diffusionsurvey,
  url = {https://arxiv.org/abs/2209.00796},
  author = {Yang, Ling and Zhang, Zhilong and Song, Yang and Hong, Shenda and Xu, Runsheng and Zhao, Yue and Shao, Yingxia and Zhang, Wentao and Cui, Bin and Yang, Ming-Hsuan},
  title = {Diffusion Models: A Comprehensive Survey of Methods and Applications},
  year = {2022},
}

@inproceedings{ho2020ddpm,
 author = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Denoising Diffusion Probabilistic Models},
 url = {https://proceedings.neurips.cc/paper/2020/file/4c5bcfec8584af0d967f1ab10179ca4b-Paper.pdf},
 year = {2020}
}

@InProceedings{sohldickstein2015deepunsupervised,
  title = 	 {Deep Unsupervised Learning using Nonequilibrium Thermodynamics},
  author = 	 {Sohl-Dickstein, Jascha and Weiss, Eric and Maheswaranathan, Niru and Ganguli, Surya},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
  year = 	 {2015},
  url = 	 {https://proceedings.mlr.press/v37/sohl-dickstein15.html},
  abstract = 	 {A central problem in machine learning involves modeling complex data-sets using highly flexible families of probability distributions in which learning, sampling, inference, and evaluation are still analytically or computationally tractable. Here, we develop an approach that simultaneously achieves both flexibility and tractability. The essential idea, inspired by non-equilibrium statistical physics, is to systematically and slowly destroy structure in a data distribution through an iterative forward diffusion process. We then learn a reverse diffusion process that restores structure in data, yielding a highly flexible and tractable generative model of the data. This approach allows us to rapidly learn, sample from, and evaluate probabilities in deep generative models with thousands of layers or time steps, as well as to compute conditional and posterior probabilities under the learned model. We additionally release an open source reference implementation of the algorithm.}
}
@inproceedings{karras2022edm,
  author    = {Tero Karras and Miika Aittala and Timo Aila and Samuli Laine},
  title     = {Elucidating the Design Space of Diffusion-Based Generative Models},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2022}
}

@article{song2017pixeldefend,
  title   = {Pixeldefend: Leveraging generative models to understand and defend against adversarial examples},
  author  = {Song, Yang and Kim, Taesup and Nowozin, Sebastian and Ermon, Stefano and Kushman, Nate},
  journal = {arXiv preprint arXiv:1710.10766},
  year    = {2017}
}
@inproceedings{song2019generative,
  title     = {Generative modeling by estimating gradients of the data distribution},
  author    = {Song, Yang and Ermon, Stefano},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  volume    = {32},
  year      = {2019}
}
@inproceedings{song2019sliced,
  author    = {Yang Song and
               Sahaj Garg and
               Jiaxin Shi and
               Stefano Ermon},
  title     = {Sliced Score Matching: {A} Scalable Approach to Density and Score
               Estimation},
  booktitle = {Proceedings of the Thirty-Fifth Conference on Uncertainty in Artificial
               Intelligence, {UAI} 2019, Tel Aviv, Israel, July 22-25, 2019},
  pages     = {204},
  year      = {2019},
  url       = {http://auai.org/uai2019/proceedings/papers/204.pdf}
}
@inproceedings{song2021ddim,
  title     = {Denoising Diffusion Implicit Models},
  author    = {Song, Jiaming and Meng, Chenlin and Ermon, Stefano},
  booktitle = {International Conference on Learning Representations (ICLR)},
  year      = {2021}
}
@inproceedings{song2020improved,
  title     = {Improved techniques for training score-based generative models},
  author    = {Song, Yang and Ermon, Stefano},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  volume    = {33},
  pages     = {12438--12448},
  year      = {2020}
}
@inproceedings{song2020scoreSDE,
  title     = {Score-Based Generative Modeling through Stochastic Differential Equations},
  author    = {Song, Yang and Sohl-Dickstein, Jascha and Kingma, Diederik P and Kumar, Abhishek and Ermon, Stefano and Poole, Ben},
  booktitle = {International Conference on Learning Representations},
  year      = {2020}
}
@inproceedings{song2021maximum,
  title     = {Maximum likelihood training of score-based diffusion models},
  author    = {Song, Yang and Durkan, Conor and Murray, Iain and Ermon, Stefano},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  volume    = {34},
  pages     = {1415--1428},
  year      = {2021}
}
@inproceedings{song2021solving,
  title     = {Solving Inverse Problems in Medical Imaging with Score-Based Generative Models},
  author    = {Song, Yang and Shen, Liyue and Xing, Lei and Ermon, Stefano},
  booktitle = {International Conference on Learning Representations},
  year      = {2021}
}
@inproceedings{lou2023reflected,
      title={Reflected Diffusion Models},
      author={Aaron Lou and Stefano Ermon},
      booktitle={International Conference on Machine Learning},
      year={2023},
}
@article{song2021train,
  title   = {How to train your energy-based models},
  author  = {Song, Yang and Kingma, Diederik P},
  journal = {arXiv preprint arXiv:2101.03288},
  year    = {2021}
}
@article{song2022applying,
  title   = {Applying Regularized {S}chr{รถ}dinger-Bridge-Based Stochastic Process in Generative Modeling},
  author  = {Song, Ki-Ung},
  journal = {arXiv preprint arXiv:2208.07131},
  year    = {2022}
}

@inproceedings{bansal2022cold,
  title={Cold Diffusion: Inverting Arbitrary Image Transforms Without Noise},
  author={Arpit Bansal and Eitan Borgnia and Hong-Min Chu and Jie S. Li and Hamid Kazemi and Furong Huang and Micah Goldblum and Jonas Geiping and Tom Goldstein},
  year={2023},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  url={https://arxiv.org/abs/2208.09392}
}

%%%%%%%%%%% Video diffusion models
@inproceedings{voleti2022mcvd,
  title={MCVD: Masked Conditional Video Diffusion for Prediction, Generation, and Interpolation},
  url = {https://arxiv.org/abs/2205.09853},
  author = {Voleti, Vikram and Jolicoeur-Martineau, Alexia and Pal, Christopher},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year = {2022}
}

@article{ho2022videodiffusion,
    title={Video diffusion models},
    author={Ho, Jonathan and Salimans, Tim and Gritsenko, Alexey and Chan, William and Norouzi, Mohammad and Fleet, David J},
    journal={Advances in Neural Information Processing Systems (NeurIPS)},
    year={2022}}
}

@article{singer2022makeavideo,
  url = {https://arxiv.org/abs/2209.14792},
  author = {Singer, Uriel and Polyak, Adam and Hayes, Thomas and Yin, Xi and An, Jie and Zhang, Songyang and Hu, Qiyuan and Yang, Harry and Ashual, Oron and Gafni, Oran and Parikh, Devi and Gupta, Sonal and Taigman, Yaniv},
  title = {Make-A-Video: Text-to-Video Generation without Text-Video Data},
  year = {2022}
}

@article{ho2022imagenvideo,
  url = {https://arxiv.org/abs/2210.02303},
  author = {Ho, Jonathan and Chan, William and Saharia, Chitwan and Whang, Jay and Gao, Ruiqi and Gritsenko, Alexey and Kingma, Diederik P. and Poole, Ben and Norouzi, Mohammad and Fleet, David J. and Salimans, Tim},
  title = {Imagen Video: High Definition Video Generation with Diffusion Models},
  year = {2022}
}
@article{harvey2022flexiblevideos,
  title   = {Flexible Diffusion Modeling of Long Videos},
  author  = {Harvey, William and Naderiparizi, Saeid and Masrani, Vaden and Weilbach, Christian and Wood, Frank},
  journal = {Advances in Neural Information Processing Systems (NeurIPS)},
  year    = {2022}
}

@article{yang2022diffusion,
  title   = {Diffusion probabilistic modeling for video generation},
  author  = {Yang, Ruihan and Srivastava, Prakhar and Mandt, Stephan},
  journal = {arXiv preprint arXiv:2203.09481},
  year    = {2022}
}
